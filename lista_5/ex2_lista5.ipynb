{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras import initializers, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data() # carregar dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "num_labels = len(np.unique(y_train))\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "image_size = x_train.shape[1] # salvando o tamanho da imagem\n",
    "x_train = x_train.astype('float32') / 255 # normalizacao\n",
    "x_test = x_test.astype('float32') / 255 # normalizacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "[n,height,width,numChannels] = x_train.shape\n",
    "input_shape = (height, width, numChannels) # formato da camada de entrada\n",
    "batch_size = 32\n",
    "kernel_size = 3 # kernel 3x3\n",
    "pool_size = 2\n",
    "filters = 32\n",
    "dropout = 0.2 # dropout rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 15, 15, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 4, 4, 64)          36928     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                65600     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122,570\n",
      "Trainable params: 122,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# Foram utilizadas dois conjuntos de camadas compostas por uma camada convolucional com função de ativacao ReLu e uma camada de max pooling\n",
    "\n",
    "# ========= primeiro conjunto =========================== \n",
    "model.add(Conv2D(filters=filters,\n",
    "                 kernel_size=kernel_size,\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "# dim = (30x30x32)\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "# o pooling, como eh igual a 2, diminui a dimensao pela metade\n",
    "# dim = (15x15x32)\n",
    "# ========= primeiro conjunto ===========================\n",
    "\n",
    "# ========= segundo conjunto ===========================\n",
    "# neste conjunto foram utilizados o dobro de filtros\n",
    "model.add(Conv2D(filters=2*filters,\n",
    "                 kernel_size=kernel_size,\n",
    "                 activation='relu'))\n",
    "# dim = (13x13x64)\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "# dim = (6x6x64)\n",
    "# ========= segundo conjunto ===========================\n",
    "\n",
    "# foi entao adicionada mais uma camada de convolucao\n",
    "model.add(Conv2D(filters=2*filters,\n",
    "                 kernel_size=kernel_size,\n",
    "                 activation='relu'))\n",
    "# dim = (4x4x64)\n",
    "\n",
    "# redefinindo a dimensao\n",
    "model.add(Flatten())\n",
    "# dim = (1024)\n",
    "\n",
    "# reducao da dimensao com uma camada fully connected\n",
    "model.add(Dense(units=2*filters,activation='softmax'))\n",
    "# dim = (64)\n",
    "\n",
    "# camada dropout para evitar o overfitting\n",
    "model.add(Dropout(dropout))\n",
    "# a camada dropout nao altera a dimensao\n",
    "\n",
    "# camada de saida\n",
    "model.add(Dense(units=num_labels,activation='sigmoid'))\n",
    "# dim = (10)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# foi utilizada a Categorical Crossentropy como loss function, visto queeh um problema com multiplas classes\n",
    "# neste caso o otimizador Adam perfomou melhor do que o SGD, entao este foi escolhido\n",
    "model.compile(loss=losses.CategoricalCrossentropy(from_logits=False),\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 28s 17ms/step - loss: 2.0883 - accuracy: 0.2168 - val_loss: 1.8802 - val_accuracy: 0.3304\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 1.8352 - accuracy: 0.3149 - val_loss: 1.6716 - val_accuracy: 0.4031\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 1.6526 - accuracy: 0.3966 - val_loss: 1.4757 - val_accuracy: 0.5102\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 1.4788 - accuracy: 0.4750 - val_loss: 1.2737 - val_accuracy: 0.5823\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 1.3610 - accuracy: 0.5088 - val_loss: 1.2242 - val_accuracy: 0.5916\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 1.3000 - accuracy: 0.5273 - val_loss: 1.1491 - val_accuracy: 0.6116\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 35s 22ms/step - loss: 1.2456 - accuracy: 0.5489 - val_loss: 1.1207 - val_accuracy: 0.6237\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 36s 23ms/step - loss: 1.1963 - accuracy: 0.5675 - val_loss: 1.0547 - val_accuracy: 0.6427\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 35s 23ms/step - loss: 1.1488 - accuracy: 0.5895 - val_loss: 1.0478 - val_accuracy: 0.6452\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 36s 23ms/step - loss: 1.1122 - accuracy: 0.6033 - val_loss: 1.0174 - val_accuracy: 0.6633\n",
      "\n",
      "Test accuracy: 66.3%\n"
     ]
    }
   ],
   "source": [
    "# a principio foram utilizadas 10 epocas para treinamento, visto que nao estava avendo uma variacao consideravel da acuracia com mais epocas\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=batch_size, validation_data=(x_test, y_test))\n",
    "\n",
    "_, acc = model.evaluate(x_test,\n",
    "                        y_test,\n",
    "                        batch_size=batch_size,\n",
    "                        verbose=0)\n",
    "print(\"\\nTest accuracy: %.1f%%\" % (100.0 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# neste trecho foi feita uma tentativa de classificar uma imagem de cachorro usando a rede construida\n",
    "\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "# leitura da imagem\n",
    "image = cv2.imread(\"dog_32.jpg\")\n",
    "\n",
    "# mudanca do formato para atender as restricoes de entrada da rede\n",
    "image = tf.reshape(image,[-1,32,32,3])\n",
    "result = model.predict(image)\n",
    "result = np.argmax(result)\n",
    "\n",
    "# o resultado obtido foi a classe 5, justamente a que representa o cachorro\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1fe4583b8cdbc727a11418515755694579336c566bf16e2a447a66de6ccdfd9c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
